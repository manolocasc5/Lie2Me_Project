import streamlit as st
import cv2
import numpy as np
import tempfile
import time
import video_utils as vu # Importa tu m√≥dulo de utilidades
import tensorflow as tf
import pandas as pd
import os
import subprocess # Necesario para ejecutar comandos FFmpeg

# --- Configuraci√≥n de la p√°gina de Streamlit ---
st.set_page_config(page_title="Lie2Me - Emociones en tiempo real", layout="wide")
st.title("üé≠ Lie2Me - Detecci√≥n de emociones y predisposici√≥n")

# --- Inicializar y verificar el clasificador de Haar ---
face_cascade_status_message, face_cascade_loaded_successfully = vu.init_face_cascade_classifier()

if face_cascade_loaded_successfully:
    st.sidebar.success(face_cascade_status_message)
else:
    st.sidebar.error(face_cascade_status_message)
    st.stop() # Detener la aplicaci√≥n si el clasificador no carga, ya que la detecci√≥n facial es cr√≠tica

# --- Carga del modelo TensorFlow (cacheado para eficiencia) ---
@st.cache_resource
def cargar_modelo():
    try:
        model_path = "model/mobilenetv2_emotion_binario_finetune.h5"
        if not os.path.exists(model_path):
            st.error(f"Error: El archivo del modelo no se encuentra en la ruta: {model_path}")
            st.stop()
        model = tf.keras.models.load_model(model_path)
        return model
    except Exception as e:
        st.error(f"Error al cargar el modelo de TensorFlow: {e}")
        st.info("Aseg√∫rate de que 'model/mobilenetv2_emotion_binario_finetune.h5' existe y es compatible con tu versi√≥n de TensorFlow.")
        st.stop()

model = cargar_modelo()

# --- Variables para almacenar resultados globales ---
predicciones_totales = []
frames_procesados_para_guardar = []

# --- Sidebar: Selecci√≥n de la fuente de video ---
fuente = st.sidebar.radio("Selecciona la fuente de video:", ("C√°mara en vivo", "Subir video"))

# --- Funci√≥n para procesar un solo frame ---
def procesar_frame(frame_input):
    boxes = vu.detectar_rostros(frame_input)
    preds_en_frame = []

    for box in boxes:
        rostro = vu.extraer_region_rostro(frame_input, box)
        if rostro is not None:
            img_proc = vu.preprocesar_imagen(rostro)
            pred = vu.predecir_emocion(model, img_proc)
            preds_en_frame.append(pred)
            
            texto = f"Predispuesto ({pred:.2f})" if pred > 0.5 else f"No predispuesto ({pred:.2f})"
            color = (0, 255, 0) if pred > 0.5 else (0, 0, 255)

            vu.dibujar_caja_y_texto(frame_input, box, texto, color=color)
        else:
            preds_en_frame.append(None)
    return frame_input, boxes, preds_en_frame

# --- L√≥gica principal basada en la fuente de video ---
stframe = st.empty()

if fuente == "C√°mara en vivo":
    st.write("üé• Capturando desde c√°mara por 5 segundos...")
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        st.error("Error: No se pudo acceder a la c√°mara. Aseg√∫rate de que est√© conectada y no est√© en uso por otra aplicaci√≥n.")
        st.stop()

    start_time = time.time()
    duration = 5
    
    while time.time() - start_time < duration:
        ret, frame = cap.read()
        if not ret:
            st.warning("No se pudo leer el frame desde la c√°mara. Intentando de nuevo...")
            time.sleep(0.1)
            continue

        processed_frame, current_boxes, current_preds = procesar_frame(frame)
        predicciones_totales.extend([p for p in current_preds if p is not None])
        frames_procesados_para_guardar.append(processed_frame.copy())

        frame_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
        stframe.image(frame_rgb, channels="RGB")

    cap.release()

elif fuente == "Subir video":
    uploaded_file = st.file_uploader("Sube un archivo de video", type=["mp4", "avi", "mov"])
    
    if uploaded_file is not None:
        # 1. Guardar el archivo subido en un archivo temporal
        original_video_path = ""
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile:
            tfile.write(uploaded_file.read())
            original_video_path = tfile.name

        # 2. Determinar la ruta para el video procesado
        processed_video_path = original_video_path.replace(".mp4", "_processed.mp4")
        # Aseg√∫rate de que la extensi√≥n sea .mp4 para la salida, aunque la entrada sea .MOV
        if not processed_video_path.endswith(".mp4"):
            processed_video_path = processed_video_path + ".mp4"
            
        st.info("Detectando y corrigiendo la orientaci√≥n del video (si es necesario)...")
        
        # --- APLICAR TRANSFORMACI√ìN DE ROTACI√ìN USANDO FFmpeg ---
        # Aqu√≠ es donde integramos la l√≥gica de correcci√≥n que encontraste.
        # Basado en tu experiencia, usaremos el comando que te funcion√≥.
        # Es crucial que FFmpeg est√© accesible en el PATH del sistema donde se ejecuta la app.
        
        # Puedes intentar el comando que te funcion√≥:
        ffmpeg_command = [
            "ffmpeg",
            "-i", original_video_path,
            "-vf", "transpose=2,transpose=2,transpose=1,transpose=1", # El filtro que te funcion√≥
            "-c:v", "libx264", # Recodificar video (libx264 es un c√≥dec MP4 com√∫n)
            "-preset", "fast", # Velocidad de codificaci√≥n (puedes ajustar)
            "-crf", "23", # Calidad (menor valor = mayor calidad/tama√±o)
            "-c:a", "aac", # Recodificar audio a AAC para compatibilidad MP4
            "-b:a", "128k", # Bitrate de audio
            "-y", # Sobrescribir archivo de salida si existe
            processed_video_path
        ]
        
        # O, si sabes que el problema es la displaymatrix y quieres ignorarla:
        # ffmpeg_command = [
        #     "ffmpeg",
        #     "-noautorotate", # Ignorar metadatos de rotaci√≥n
        #     "-i", original_video_path,
        #     "-vf", "transpose=1", # O el transpose que sea necesario para este caso
        #     "-c:v", "libx264", 
        #     "-preset", "fast", 
        #     "-crf", "23", 
        #     "-c:a", "aac", 
        #     "-b:a", "128k", 
        #     "-y", 
        #     processed_video_path
        # ]

        try:
            # Ejecutar el comando FFmpeg
            process = subprocess.run(ffmpeg_command, capture_output=True, text=True, check=True)
            st.success("Video pre-procesado para corregir orientaci√≥n.")
            # Opcional: mostrar stdout/stderr de ffmpeg para depuraci√≥n
            # st.text("FFmpeg STDOUT:\n" + process.stdout)
            # st.text("FFmpeg STDERR:\n" + process.stderr)

        except subprocess.CalledProcessError as e:
            st.error(f"Error al pre-procesar el video con FFmpeg: {e.stderr}")
            st.warning("Intentando procesar el video original sin correcci√≥n de rotaci√≥n. Podr√≠a aparecer invertido.")
            processed_video_path = original_video_path # Volver al original si falla la correcci√≥n
        except FileNotFoundError:
            st.error("Error: FFmpeg no encontrado. Aseg√∫rate de que FFmpeg est√° instalado y en tu PATH.")
            st.warning("Intentando procesar el video original sin correcci√≥n de rotaci√≥n. Podr√≠a aparecer invertido.")
            processed_video_path = original_video_path # Volver al original si FFmpeg no est√°
        except Exception as e:
            st.error(f"Error inesperado durante el pre-procesamiento: {e}")
            st.warning("Intentando procesar el video original sin correcci√≥n de rotaci√≥n. Podr√≠a aparecer invertido.")
            processed_video_path = original_video_path # Volver al original si hay otro error

        # 3. Abrir el video PROCESADO (o el original si hubo error)
        cap = cv2.VideoCapture(processed_video_path)
        
        if not cap.isOpened():
            st.error(f"Error: No se pudo abrir el archivo de video: {os.path.basename(processed_video_path)}. ¬øEs un archivo de video v√°lido despu√©s del procesamiento?")
            # Limpia archivos temporales
            if os.path.exists(original_video_path): os.unlink(original_video_path)
            if os.path.exists(processed_video_path): os.unlink(processed_video_path)
            st.stop()

        # Ya no necesitamos get_video_rotation aqu√≠ porque FFmpeg ya fijo la rotaci√≥n
        rotation_angle = 0 # Asumimos 0 porque ya est√° rotado a nivel de p√≠xel
        
        MAX_FRAME_WIDTH = 800 

        progress_bar = st.progress(0)
        frame_count = 0
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        if total_frames == 0: 
            st.warning("El video parece estar vac√≠o o corrupto (0 frames) despu√©s del procesamiento.")
            cap.release()
            if os.path.exists(original_video_path): os.unlink(original_video_path)
            if os.path.exists(processed_video_path): os.unlink(processed_video_path)
            st.stop()

        st.write(f"Procesando video: {total_frames} frames...")

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # No es necesario aplicar vu.rotate_frame_if_needed aqu√≠
            # porque FFmpeg ya lo hizo a nivel de p√≠xel.
            
            current_height, current_width, _ = frame.shape
            if current_width > MAX_FRAME_WIDTH:
                new_width = MAX_FRAME_WIDTH
                new_height = int(current_height * (MAX_FRAME_WIDTH / current_width))
                frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_AREA)

            processed_frame, current_boxes, current_preds = procesar_frame(frame)
            predicciones_totales.extend([p for p in current_preds if p is not None])
            frames_procesados_para_guardar.append(processed_frame.copy())

            frame_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
            stframe.image(frame_rgb, channels="RGB")

            frame_count += 1
            progress_bar.progress(min(100, int((frame_count / total_frames) * 100)))

        cap.release()
        # Eliminar ambos archivos temporales al finalizar
        if os.path.exists(original_video_path): os.unlink(original_video_path)
        if os.path.exists(processed_video_path): os.unlink(processed_video_path)

# --- Resto de la secci√≥n de resultados y descargas (sin cambios funcionales importantes) ---
if predicciones_totales:
    st.markdown("---")
    st.header("üìä Resultados del An√°lisis")

    count_pos = sum(1 for p in predicciones_totales if p is not None and p > 0.5)
    count_neg = sum(1 for p in predicciones_totales if p is not None and p <= 0.5)
    
    total_preds_validas = len([p for p in predicciones_totales if p is not None])

    st.write(f"‚úÖ **Frames/Rostros Predispuestos:** {count_pos} de {total_preds_validas}")
    st.write(f"‚ùå **Frames/Rostros No Predispuestos:** {count_neg} de {total_preds_validas}")

    if total_preds_validas > 0:
        if count_pos > count_neg:
            st.success("‚úÖ **Conclusi√≥n:** La mayor√≠a de las detecciones indican una **predisposici√≥n a repetir la experiencia**.")
        elif count_neg > count_pos:
            st.error("‚ùå **Conclusi√≥n:** La mayor√≠a de las detecciones indican **no predisposici√≥n a repetir la experiencia**.")
        else:
            st.info("‚ÑπÔ∏è **Conclusi√≥n:** Las detecciones de predisposici√≥n y no predisposici√≥n est√°n equilibradas.")
    else:
        st.warning("No se pudieron obtener predicciones v√°lidas para la conclusi√≥n.")

    if predicciones_totales:
        fig = vu.graficar_predicciones(predicciones_totales, titulo="Evoluci√≥n de la Predisposici√≥n por Detecci√≥n")
        st.pyplot(fig)

    if predicciones_totales:
        df_preds = pd.DataFrame({
            "id_deteccion": list(range(len(predicciones_totales))),
            "prediccion_raw": predicciones_totales,
            "predisposicion": ["Predispuesto" if p > 0.5 else "No predispuesto" for p in predicciones_totales]
        })
        csv = df_preds.to_csv(index=False).encode("utf-8")
        st.download_button(
            label="‚¨áÔ∏è Descargar predicciones CSV",
            data=csv,
            file_name="predicciones_lie2me.csv",
            mime="text/csv"
        )

    if frames_procesados_para_guardar:
        output_video_filename = "video_lie2me_anotado.mp4"
        try:
            # Los FPS deben ser los del video original o un valor por defecto si no se pudo leer.
            # Aqu√≠, 'cap' es el del video *procesado*. Asumimos que su FPS es el correcto.
            fps = cap.get(cv2.CAP_PROP_FPS) if 'cap' in locals() and cap.isOpened() else 15
            if fps == 0: 
                fps = 15 
            
            success = vu.guardar_video(frames_procesados_para_guardar, output_video_filename, fps=fps)
            if success:
                with open(output_video_filename, "rb") as f:
                    st.download_button(
                        label="‚¨áÔ∏è Descargar video anotado",
                        data=f,
                        file_name=output_video_filename,
                        mime="video/mp4"
                    )
                os.remove(output_video_filename)
            else:
                st.error("No se pudo generar el video anotado para descargar.")
        except Exception as e:
            st.error(f"Error al intentar guardar o descargar el video anotado: {e}")
            st.info("Aseg√∫rate de que no haya un video con el mismo nombre abierto o de que haya suficiente espacio en disco.")
else:
    st.info("Esperando la captura o subida de video para iniciar el an√°lisis. No se han procesado frames a√∫n.")